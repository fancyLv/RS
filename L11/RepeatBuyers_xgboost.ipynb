{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T07:54:32.660665Z",
     "start_time": "2020-04-05T07:54:32.160497Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T07:55:54.871882Z",
     "start_time": "2020-04-05T07:55:18.383660Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用户行为，使用format1进行加载\n",
    "# 加载全量样本\n",
    "user_log = pd.read_csv('../data/RepeatBuyers/data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('../data/RepeatBuyers/data_format1/user_info_format1.csv')\n",
    "train_data1 = pd.read_csv('../data/RepeatBuyers/data_format1/train_format1.csv')\n",
    "submission = pd.read_csv('../data/RepeatBuyers/data_format1/test_format1.csv')\n",
    "train_data = pd.read_csv('../data/RepeatBuyers/data_format2/train_format2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T07:55:55.060861Z",
     "start_time": "2020-04-05T07:55:54.995617Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T07:56:07.660415Z",
     "start_time": "2020-04-05T07:55:55.122951Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix.drop(['prob'], axis=1, inplace=True)\n",
    "# 连接user_info表，通过user_id关联\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')\n",
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n",
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T07:56:07.791819Z",
     "start_time": "2020-04-05T07:56:07.735718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del user_info, train_data1\n",
    "gc.collect()\n",
    "# print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:01:44.957219Z",
     "start_time": "2020-04-05T07:56:11.781160Z"
    }
   },
   "outputs": [],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "# 统计操作类型为0，1，2，3的个数\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "#print(matrix)\n",
    "\n",
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "#print(matrix)\n",
    "\n",
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
    "#print(matrix)\n",
    "\n",
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "# print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:01:45.799187Z",
     "start_time": "2020-04-05T08:01:45.138592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
    "del temp, matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:01:46.430139Z",
     "start_time": "2020-04-05T08:01:45.952147Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用机器学习工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:01:46.661156Z",
     "start_time": "2020-04-05T08:01:46.578486Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将训练集进行切分，20%用于验证\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)\n",
    "\n",
    "# 使用XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:02:09.758757Z",
     "start_time": "2020-04-05T08:01:46.848808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.633251\tvalidation_1-auc:0.615093\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.648862\tvalidation_1-auc:0.627651\n",
      "[2]\tvalidation_0-auc:0.653955\tvalidation_1-auc:0.631598\n",
      "[3]\tvalidation_0-auc:0.657159\tvalidation_1-auc:0.633941\n",
      "[4]\tvalidation_0-auc:0.659495\tvalidation_1-auc:0.634143\n",
      "[5]\tvalidation_0-auc:0.662077\tvalidation_1-auc:0.63571\n",
      "[6]\tvalidation_0-auc:0.662373\tvalidation_1-auc:0.636345\n",
      "[7]\tvalidation_0-auc:0.66456\tvalidation_1-auc:0.639077\n",
      "[8]\tvalidation_0-auc:0.666051\tvalidation_1-auc:0.640122\n",
      "[9]\tvalidation_0-auc:0.666883\tvalidation_1-auc:0.640663\n",
      "[10]\tvalidation_0-auc:0.667606\tvalidation_1-auc:0.640413\n",
      "[11]\tvalidation_0-auc:0.668174\tvalidation_1-auc:0.641615\n",
      "[12]\tvalidation_0-auc:0.668778\tvalidation_1-auc:0.642617\n",
      "[13]\tvalidation_0-auc:0.669174\tvalidation_1-auc:0.642987\n",
      "[14]\tvalidation_0-auc:0.669725\tvalidation_1-auc:0.643457\n",
      "[15]\tvalidation_0-auc:0.671105\tvalidation_1-auc:0.644588\n",
      "[16]\tvalidation_0-auc:0.671609\tvalidation_1-auc:0.645179\n",
      "[17]\tvalidation_0-auc:0.671778\tvalidation_1-auc:0.644676\n",
      "[18]\tvalidation_0-auc:0.671924\tvalidation_1-auc:0.644333\n",
      "[19]\tvalidation_0-auc:0.671515\tvalidation_1-auc:0.643566\n",
      "[20]\tvalidation_0-auc:0.67165\tvalidation_1-auc:0.642966\n",
      "[21]\tvalidation_0-auc:0.671846\tvalidation_1-auc:0.643321\n",
      "[22]\tvalidation_0-auc:0.672155\tvalidation_1-auc:0.643327\n",
      "[23]\tvalidation_0-auc:0.672384\tvalidation_1-auc:0.642841\n",
      "[24]\tvalidation_0-auc:0.672583\tvalidation_1-auc:0.642914\n",
      "[25]\tvalidation_0-auc:0.672542\tvalidation_1-auc:0.642913\n",
      "[26]\tvalidation_0-auc:0.672796\tvalidation_1-auc:0.643335\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-auc:0.671609\tvalidation_1-auc:0.645179\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eta=0.3, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=300, missing=None, n_estimators=1000, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='auc', eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=True,\n",
    "    #早停法，如果auc在10epoch没有进步就stop\n",
    "    early_stopping_rounds=10 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:12:35.550675Z",
     "start_time": "2020-04-05T08:02:09.982881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eta=0.3, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=300, missing=None, n_estimators=1000, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:12:37.307528Z",
     "start_time": "2020-04-05T08:12:35.826570Z"
    }
   },
   "outputs": [],
   "source": [
    "prob = model.predict_proba(test_data)\n",
    "submission['prob'] = pd.Series(prob[:,1])\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python37464bittensorflowconda8d92e938f73742f8962ec619222b1557"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "344px",
    "left": "1044px",
    "right": "20px",
    "top": "142px",
    "width": "626px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
